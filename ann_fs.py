# -*- coding: utf-8 -*-
"""ANN FS

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NdX4oHd2Zt84WaGh3-pYD73iBYlmPT9G
"""

import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns

dataset = pd.read_csv('heart.csv')

dataset.head()

X = dataset.iloc[:, 3:-1].values
Y = dataset.iloc[:, -1].values

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
X[:, 2] = le.fit_transform(X[:, 2])

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1, random_state = 0)
X_train.shape, Y_train.shape, X_test.shape, Y_test.shape

dataset.duplicated().sum()

dataset[dataset.duplicated()]

duplicated_features = dataset[dataset.duplicated()].index.values
print(duplicated_features)

unique_df = dataset.drop_duplicates(keep='first').T
unique_df.shape

removed_features = [col for col in dataset.columns if col not in unique_df.columns]
removed_features

from sklearn.feature_selection import VarianceThreshold
feature_selector = VarianceThreshold(threshold=0)
feature_selector.fit(X_train)

feature_selector.get_support()

sum(feature_selector.get_support())

X_train = feature_selector.transform(X_train)
X_test = feature_selector.transform(X_test)
X_train.shape, X_test.shape

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

ann = tf.keras.models.Sequential()

ann.add(tf.keras.layers.Dense(units=6, activation='relu'))

ann.add(tf.keras.layers.Dense(units=6, activation='relu'))

ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))

ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

history=ann.fit(X_train, Y_train, batch_size = 32, epochs =50,validation_data=(X_test,Y_test))

history.history.keys()

loss=history.history['loss']
val_loss=history.history['val_loss']
epochs=range(1, len(loss)+1)
#acc=history.history['accuracy']
#val_acc=history.history['val_accuracy']
plt.plot(epochs,loss,'y',label='Training loss ')
plt.plot(epochs,val_loss,'r',label='Validation loss ')
plt.title('Training and Validation Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend()
plt.show()

acc=history.history['accuracy']
val_acc=history.history['val_accuracy']
plt.plot(epochs,acc,'y',label='Training Accuracy')
plt.plot(epochs,val_acc,'r',label='Validation Accuracy ')
plt.title('Training and Validation Accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend()
plt.show()

from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve
from tensorflow import keras
probs=ann.predict(X_test)
probs=probs[:,0]
auc=roc_auc_score(Y_test,probs)
print(auc)
fpr,tpr,thresh=roc_curve(Y_test,probs)
plt.plot([0,1],[0,1],linestyle='--')
plt.plot(fpr,tpr,marker=".",color="red")